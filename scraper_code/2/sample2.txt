Waymo Operates Vacant But Is Suprisingly Bold With Erratic Driver performance.mark = performance.mark || function(s) {}; performance.mark('content_title_end'); Brad Templeton Contributor Opinions expressed by Forbes Contributors are their own. Transportation I cover robocar technology & previously worked on Google's car team. Share to facebook Share to twitter Share to linkedin Close-up of self driving minivan, with LIDAR and other sensor units and logo visible, part of Google ... [+] parent company Alphabet Inc, driving past historic railroad station with sign reading Mountain View, in the Silicon Valley town of Mountain View, California, with safety driver visible, October 28, 2018. (Photo by Smith Collection/Gado/Getty Images)Getty ImagesA recent video was published by a driver who encountered one of Waymos minivans in Arizona operating entirely vacant. Waymo has been doing limited completely unmanned operations on a small scale for some time, but its been rare for people to encounter these in the wild. That Waymo approved even limited operations of this type was a monumental feat, because it says that Waymos own teams of engineers and lawyers agreed they had reached the point where this was safe to do safe for the public, and safe for the companys reputation. Safe enough to do in the Phoenix area, where Uber killed a pedestrian and public tolerance for any incident would be low. Safe enough to bet their multi-billion dollar project valued by people like Morgan Stanley at over $100B on. For a solid team to make that bet says a lot; it almost surely needed to be approved all the way up to the Alphabet board.I named the decision to go unmanned one of the biggest milestones in robocar history back in March of 2018, not knowing that just a few days later, the Uber fatality would knock it down a peg.And so far, these operations have been safe with no reported incidents. While the vehicles are unmanned, they are well connected back to Waymo HQ, where people in an operations center can look out the vehicles cameras and other sensors and help it if it encounters a problem it doesnt understand. They dont drive the car in real time, rather, they give it strategic advice about where to drive in a strange situation, and when to go the car still makes the steering and braking decisions.Unfortunately, in this video there is something odd, which begins around the 1:05 mark. The person making the video is excited and driving erratically and illegally. The Waymo van pulls up to a stop sign to make a left turn, and puts on its turn signal. The video car then pulls up next to it on the left in order to shoot the empty drivers seat and thus is driving the wrong way in the oncoming lane. The videographer also pauses at the stop sign, which the Waymo car waits for, and then it proceeds, with no additional delay, to make its left turn, cutting right in front of the illegal driver. That driver then follows it and returns to the legal lane.What the Waymo van did is not illegal, and nothing happened, because this wasnt a crazy driver, but just an over-eager human making use of the whole road on a mostly empty street, something human drivers do all the time for various reasons. The Waymo van had the right-of-way and the video car was stopped. At the same time it is surprising that a robocar would not switch into a mode of great caution in the presence of a driver driving the wrong direction in a lane, particularly when it comes to cutting left right in front of that vehicle, even when it has just stopped. A human driver would actually be able to see the video camera and figure out what was going on here, and know it was probably safe, but Im fairly confident the car isnt that smart. My most likely conclusion is that the car did not become cautious because the other car was in the other lane, everybody was stopped, and there was no conflict of right-of-way.Its also possible that Waymos operations center was aware they had somebody trailing the van this happens, and probably happens more with an unmanned van and that they gave the order to go using human knowledge. Waymo has informed me that the van did detect the video car driving to the left of it, and stayed stopped at the sign while it was moving, but after the video car came to a full stop, it decided it was safe to make its left turn. They have not yet given any comment on operations center involvement.It is, of course, not entirely fair to add to a robocars burden the extra problem of human drivers acting strangely because the robocar is there. Thats not something most human drivers have to worry about. On the other hand, there has been criticism of Waymo and other robocars as to how they handle avoiding being in accidents that are not their fault. Waymos record has been exemplary over 10 million miles of driving with only one at-fault accident attributed to the software. Thats far better than human drivers. (Of course, no human would drive 10 milion miles in a lifetime.) They have had several accidents where they were not at fault under the law, and some have challenged that robocars, in their quest for safety, should also be better than humans at preventing even those accidents, at least where it is possible to do so. Had the crazy videographer continued driving from the stop sign, there might have been a fender bender. (On the other hand, at these low speeds, the Waymo van might well have been able to brake hard and avoid that, depending on timing. An empty van has no fear of extremely hard braking. As such, we might judge the decision as fully safe.)With all these factors, I dont think this is some major incident for Waymo (even with the worst presumptions.) The main area of concern is that this was seen on one of the few videos ever released by a 3rd party of their unmanned operations. When something odd happens the first time, it naturally raises concern over how many odd things are going on, but anecdotes are not data.Its also worth noting that the unprotected left turn is a situation where Waymo has received a lot of criticism for being too conservative and pausing too long. One of the great challenges of such projects is finding the right, but still suitably low risk, balance on such decisions. A frequent refrain from developers is that one of the big challenges in robocars right now is getting better at predicting what others on the street are going to do, a skill at which humans currently surpass robots in many ways. This includes predicting what law-breaking and strangely acting humans will do, and when to be cautious around them. If this is an error by the Waymo system, it will quickly enter their test suite, and a variety of versions of it will be created in their simulator, so they can tells all new versions of the software against drivers of this type, and do the right thing. Simulator is the only place to extensively test what vehicles will do when they encounter erratic or illegal driving, and Waymo boasts over 10 billion miles of simulated testing and growing. The right thing, by the way, may not be that different from what the van did stop until the erratic car stops and proceed with caution. Something not currently available to the robocar is what a human driver would have done made eye contact with the illegal driver and come to some sort of non-verbal agreement about who was going. Robocar developers know this arrow is not in their quiver, though many alternatives have been explored, mostly involving car body language.My personal view is as follows. The presence of an erratic driver should trigger a state of enhanced caution, making the car more conservative. Since the normal prediction for a car that has come to a stop at a stop sign is that it is about to go if the road is clear, the planner should have predicted a risk that the vans planned path (left turn) and the cars predicted path (proceed in any direction after stop) might intersect, and acted accordingly, even though the car was in the wrong lane and did not have ROW. In normal situations, a car which passes you in the oncoming lane often wants to get ahead of you. This should trigger a request for ops assistance, or other actions. However, because at very low speeds it is safe to go because you can stop, Waymos action created low but non-zero risk.Read/leave comments on this article Follow me on Twitter or LinkedIn. Check out my website. Disclosure: The author worked on Google's car project in its early years and owns some GOOG stock. Brad Templeton I founded ClariNet, the world's first internet based business,am Chairman Emeritus of the Electronic Frontier Foundation, and a director of the Foresight Institut... Read More Print Site Feedback Tips Corrections Reprints & Permissions Terms Privacy 2019 Forbes Media LLC. All Rights Reserved. AdChoices

